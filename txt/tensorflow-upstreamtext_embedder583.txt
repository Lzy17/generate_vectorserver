<h1>Integrate text embedders.</h1>
<p>Text embedders allow embedding text into a high-dimensional feature vector
representing its semantic meaning, which can then be compared with the feature
vector of other texts to evaluate their semantic similarity.</p>
<p>As opposed to
<a href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/text_searcher">text search</a>,
the text embedder allows computing the similarity between texts on-the-fly
instead of searching through a predefined index built from a corpus.</p>
<p>Use the Task Library <code>TextEmbedder</code> API to deploy your custom text embedder into
your mobile apps.</p>
<h2>Key features of the TextEmbedder API</h2>
<ul>
<li>
<p>Input text processing, including in-graph or out-of-graph
    <a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/text/tokenizers/bert_tokenizer.h">Wordpiece</a>
    or
    <a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/text/tokenizers/sentencepiece_tokenizer.h">Sentencepiece</a>
    tokenizations on input text.</p>
</li>
<li>
<p>Built-in utility function to compute the
    <a href="https://en.wikipedia.org/wiki/Cosine_similarity">cosine similarity</a> between
    feature vectors.</p>
</li>
</ul>
<h2>Supported text embedder models</h2>
<p>The following models are guaranteed to be compatible with the <code>TextEmbedder</code>
API.</p>
<ul>
<li>
<p>The
    <a href="https://tfhub.dev/google/lite-model/universal-sentence-encoder-qa-ondevice/1">Universal Sentence Encoder TFLite model from TensorFlow Hub</a></p>
</li>
<li>
<p>Custom models that meet the
    <a href="#model-compatibility-requirements">model compatibility requirements</a>.</p>
</li>
</ul>
<h2>Run inference in C++</h2>
<p>```c++
// Initialization.
TextEmbedderOptions options:
options.mutable_base_options()-&gt;mutable_model_file()-&gt;set_file_name(model_path);
std::unique_ptr<TextEmbedder> text_embedder = TextEmbedder::CreateFromOptions(options).value();</p>
<p>// Run inference with your two inputs, <code>input_text1</code> and <code>input_text2</code>.
const EmbeddingResult result_1 = text_embedder-&gt;Embed(input_text1);
const EmbeddingResult result_2 = text_embedder-&gt;Embed(input_text2);</p>
<p>// Compute cosine similarity.
double similarity = TextEmbedder::CosineSimilarity(
    result_1.embeddings[0].feature_vector()
    result_2.embeddings[0].feature_vector());
```</p>
<p>See the
<a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/task/text/text_embedder.h">source code</a>
for more options to configure <code>TextEmbedder</code>.</p>
<h2>Run inference in Python</h2>
<h3>Step 1: Install TensorFlow Lite Support Pypi package.</h3>
<p>You can install the TensorFlow Lite Support Pypi package using the following
command:</p>
<p><code>sh
pip install tflite-support</code></p>
<h3>Step 2: Using the model</h3>
<p>```python
from tflite_support.task import text</p>
<h1>Initialization.</h1>
<p>text_embedder = text.TextEmbedder.create_from_file(model_path)</p>
<h1>Run inference on two texts.</h1>
<p>result_1 = text_embedder.embed(text_1)
result_2 = text_embedder.embed(text_2)</p>
<h1>Compute cosine similarity.</h1>
<p>feature_vector_1 = result_1.embeddings[0].feature_vector
feature_vector_2 = result_2.embeddings[0].feature_vector
similarity = text_embedder.cosine_similarity(
    result_1.embeddings[0].feature_vector, result_2.embeddings[0].feature_vector)
```</p>
<p>See the
<a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/python/task/text/text_embedder.py">source code</a>
for more options to configure <code>TextEmbedder</code>.</p>
<h2>Example results</h2>
<p>Cosine similarity between normalized feature vectors return a score between -1
and 1. Higher is better, i.e. a cosine similarity of 1 means the two vectors are
identical.</p>
<p><code>Cosine similarity: 0.954312</code></p>
<p>Try out the simple
<a href="https://github.com/tensorflow/tflite-support/tree/master/tensorflow_lite_support/examples/task/text/desktop#textembedder">CLI demo tool for TextEmbedder</a>
with your own model and test data.</p>
<h2>Model compatibility requirements</h2>
<p>The <code>TextEmbedder</code> API expects a TFLite model with mandatory
<a href="https://www.tensorflow.org/lite/models/convert/metadata">TFLite Model Metadata</a>.</p>
<p>Three main types of models are supported:</p>
<ul>
<li>
<p>BERT-based models (see
    <a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/task/text/utils/bert_utils.h">source code</a>
    for more details):</p>
<ul>
<li>
<p>Exactly 3 input tensors (kTfLiteString)</p>
<ul>
<li>IDs tensor, with metadata name "ids",</li>
<li>Mask tensor, with metadata name "mask".</li>
<li>Segment IDs tensor, with metadata name "segment_ids"</li>
</ul>
</li>
<li>
<p>Exactly one output tensor (kTfLiteUInt8/kTfLiteFloat32)</p>
<ul>
<li>with <code>N</code> components corresponding to the <code>N</code> dimensions of the
    returned feature vector for this output layer.</li>
<li>Either 2 or 4 dimensions, i.e. <code>[1 x N]</code> or <code>[1 x 1 x 1 x N]</code>.</li>
</ul>
</li>
<li>
<p>An input_process_units for Wordpiece/Sentencepiece Tokenizer</p>
</li>
</ul>
</li>
<li>
<p>Universal Sentence Encoder-based models (see
    <a href="https://github.com/tensorflow/tflite-support/blob/master/tensorflow_lite_support/cc/task/text/utils/universal_sentence_encoder_utils.h">source code</a>
    for more details):</p>
<ul>
<li>
<p>Exactly 3 input tensors (kTfLiteString)</p>
<ul>
<li>Query text tensor, with metadata name "inp_text".</li>
<li>Response context tensor, with metadata name "res_context".</li>
<li>Response text tensor, with metadata name "res_text".</li>
</ul>
</li>
<li>
<p>Exactly 2 output tensors (kTfLiteUInt8/kTfLiteFloat32)</p>
<ul>
<li>Query encoding tensor, with metadata name "query_encoding".</li>
<li>Response encoding tensor, with metadata name "response_encoding".</li>
<li>Both with <code>N</code> components corresponding to the <code>N</code> dimensions of the
    returned feature vector for this output layer.</li>
<li>Both with either 2 or 4 dimensions, i.e. <code>[1 x N]</code> or <code>[1 x 1 x 1 x
    N]</code>.</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Any text embedder model with:</p>
<ul>
<li>An input text tensor (kTfLiteString)</li>
<li>
<p>At least one output embedding tensor (kTfLiteUInt8/kTfLiteFloat32)</p>
<ul>
<li>with <code>N</code> components corresponding to the <code>N</code> dimensions of the
    returned feature vector for this output layer.</li>
<li>Either 2 or 4 dimensions, i.e. <code>[1 x N]</code> or <code>[1 x 1 x 1 x N]</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>