<h1>BERT Question and Answer</h1>
<p>Use a TensorFlow Lite model to answer questions based on the content of a given
passage.</p>
<p>Note: (1) To integrate an existing model, try
<a href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/bert_question_answerer">TensorFlow Lite Task Library</a>.
(2) To customize a model, try
<a href="https://www.tensorflow.org/lite/models/modify/model_maker/question_answer">TensorFlow Lite Model Maker</a>.</p>
<h2>Get started</h2>
<p><img src="images/screenshot.gif" class="attempt-right" style="max-width: 300px"></p>
<p>If you are new to TensorFlow Lite and are working with Android or iOS, we
recommend exploring the following example applications that can help you get
started.</p>
<p><a class="button button-primary" href="https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/android">Android
example</a>
<a class="button button-primary" href="https://github.com/tensorflow/examples/tree/master/lite/examples/bert_qa/ios">iOS
example</a></p>
<p>If you are using a platform other than Android/iOS, or you are already familiar
with the
<a href="https://www.tensorflow.org/api_docs/python/tf/lite">TensorFlow Lite APIs</a>, you
can download our starter question and answer model.</p>
<p><a class="button button-primary" href="https://tfhub.dev/tensorflow/lite-model/mobilebert/1/metadata/1?lite-format=tflite">Download
starter model and vocab</a></p>
<p>For more information about metadata and associated fields (e.g. <code>vocab.txt</code>) see
<a href="https://www.tensorflow.org/lite/models/convert/metadata#read_the_metadata_from_models">Read
the metadata from models</a>.</p>
<h2>How it works</h2>
<p>The model can be used to build a system that can answer usersâ€™ questions in
natural language. It was created using a pre-trained BERT model fine-tuned on
SQuAD 1.1 dataset.</p>
<p><a href="https://github.com/google-research/bert">BERT</a>, or Bidirectional Encoder
Representations from Transformers, is a method of pre-training language
representations which obtains state-of-the-art results on a wide array of
Natural Language Processing tasks.</p>
<p>This app uses a compressed version of BERT, MobileBERT, that runs 4x faster and
has 4x smaller model size.</p>
<p><a href="https://rajpurkar.github.io/SQuAD-explorer/">SQuAD</a>, or Stanford Question
Answering Dataset, is a reading comprehension dataset consisting of articles
from Wikipedia and a set of question-answer pairs for each article.</p>
<p>The model takes a passage and a question as input, then returns a segment of the
passage that most likely answers the question. It requires semi-complex
pre-processing including tokenization and post-processing steps that are
described in the BERT <a href="https://arxiv.org/abs/1810.04805">paper</a> and implemented
in the sample app.</p>
<h2>Performance benchmarks</h2>
<p>Performance benchmark numbers are generated with the tool
<a href="https://www.tensorflow.org/lite/performance/benchmarks">described here</a>.</p>
<table>
  <thead>
    <tr>
      <th>Model Name</th>
      <th>Model size </th>
      <th>Device </th>
      <th>CPU</th>
    </tr>
  </thead>
  <tr>
    <td rowspan = 3>
      <a href="https://tfhub.dev/tensorflow/lite-model/mobilebert/1/metadata/1?lite-format=tflite">Mobile Bert</a>
    </td>
    <td rowspan = 3>
      100.5 Mb
    </td>
    <td>Pixel 3 (Android 10) </td>
    <td>123ms*</td>
  </tr>
   <tr>
     <td>Pixel 4 (Android 10) </td>
    <td>74ms*</td>
  </tr>
   <tr>
     <td>iPhone XS (iOS 12.4.1) </td>
    <td>257ms** </td>
  </tr>
</table>

<p>* 4 threads used.</p>
<p>** 2 threads used on iPhone for the best performance result.</p>
<h2>Example output</h2>
<h3>Passage (Input)</h3>
<blockquote>
<p>Google LLC is an American multinational technology company that specializes in
Internet-related services and products, which include online advertising
technologies, search engine, cloud computing, software, and hardware. It is
considered one of the Big Four technology companies, alongside Amazon, Apple,
and Facebook.</p>
<p>Google was founded in September 1998 by Larry Page and Sergey Brin while they
were Ph.D. students at Stanford University in California. Together they own
about 14 percent of its shares and control 56 percent of the stockholder
voting power through supervoting stock. They incorporated Google as a
California privately held company on September 4, 1998, in California. Google
was then reincorporated in Delaware on October 22, 2002. An initial public
offering (IPO) took place on August 19, 2004, and Google moved to its
headquarters in Mountain View, California, nicknamed the Googleplex. In August
2015, Google announced plans to reorganize its various interests as a
conglomerate called Alphabet Inc. Google is Alphabet's leading subsidiary and
will continue to be the umbrella company for Alphabet's Internet interests.
Sundar Pichai was appointed CEO of Google, replacing Larry Page who became the
CEO of Alphabet.</p>
</blockquote>
<h3>Question (Input)</h3>
<blockquote>
<p>Who is the CEO of Google?</p>
</blockquote>
<h3>Answer (Output)</h3>
<blockquote>
<p>Sundar Pichai</p>
</blockquote>
<h2>Read more about BERT</h2>
<ul>
<li>Academic paper: <a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for
    Language Understanding</a></li>
<li><a href="https://github.com/google-research/bert">Open-source implementation of BERT</a></li>
</ul>