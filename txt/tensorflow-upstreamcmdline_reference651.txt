<h1>Converter command line reference</h1>
<p>This page is complete reference of command-line flags used by the TensorFlow
Lite Converter's command line tool.</p>
<h2>High-level flags</h2>
<p>The following high level flags specify the details of the input and output
files. The flag <code>--output_file</code> is always required. Additionally, either
<code>--saved_model_dir</code>, <code>--keras_model_file</code> or <code>--graph_def_file</code> is required.</p>
<ul>
<li><code>--output_file</code>. Type: string. Specifies the full path of the output file.</li>
<li><code>--saved_model_dir</code>. Type: string. Specifies the full path to the directory
    containing the SavedModel.</li>
<li><code>--keras_model_file</code>. Type: string. Specifies the full path of the HDF5 file
    containing the tf.keras model.</li>
<li><code>--graph_def_file</code>. Type: string. Specifies the full path of the input
    GraphDef file frozen using
    <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py">freeze_graph.py</a>.</li>
<li><code>--output_format</code>. Type: string. Default: <code>TFLITE</code>. Specifies the format of
    the output file. Allowed values:<ul>
<li><code>TFLITE</code>: TensorFlow Lite model format.</li>
<li><code>GRAPHVIZ_DOT</code>: GraphViz <code>.dot</code> format containing a visualization of the
    graph after graph transformations. <em>Note: This only works when you set
    flag <code>experimental_new_converter=False</code>. Also, as this format leads to
    loss of TFLite specific transformations, we recommend that you use
    <code>--dump_graphviz_dir</code> instead to get a final visualization with all
    graph transformations.</em></li>
</ul>
</li>
<li><code>--experimental_new_converter</code>. Type: bool. Default: True (from TF 2.2). To
    leverage MLIR-based conversion, Google's cutting edge compiler technology
    for machine learning. This enables conversion of new classes of models,
    including Mask R-CNN, Mobile BERT, etc and supports models with functional
    control flow.</li>
</ul>
<p>The following flags specify optional parameters when using SavedModels.</p>
<ul>
<li><code>--saved_model_tag_set</code>. Type: string. Default: "serve" (for more options,
    refer to
    <a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/tag_constants.h">tag_constants.h</a>).
    Specifies a comma-separated set of tags identifying the MetaGraphDef within
    the SavedModel to analyze. All tags in the tag set must be specified.</li>
<li><code>--saved_model_signature_key</code>. Type: string. Default: "serving_default" (for
    more options, refer to
    <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/saved_model/signature_constants">tf.compat.v1.saved_model.signature_constants</a>).
    Specifies the key identifying the SignatureDef containing inputs and
    outputs.</li>
</ul>
<h2>Model flags</h2>
<p><em>Model flags</em> provide additional information about the model stored in the input
file.</p>
<ul>
<li><code>--input_arrays</code>. Type: comma-separated list of strings. Specifies the list
    of names of input tensors.</li>
<li><code>--output_arrays</code>. Type: comma-separated list of strings. Specifies the list
    of names of output tensors.</li>
</ul>
<p>The following flags define properties of the input tensors. Each item in the
<code>--input_arrays</code> flag should correspond to each item in the following flags
based on index.</p>
<ul>
<li><code>--input_shapes</code>. Type: colon-separated list of comma-separated lists of
    integers. Each comma-separated list of integers gives the shape of one of
    the input arrays.<ul>
<li>Example: <code>--input_shapes=1,60,80,3</code> for a typical vision model means a
    batch size of 1, an input image height of 60, an input image width of
    80, and an input image depth of 3 (representing RGB channels).</li>
<li>Example: <code>--input_arrays=foo,bar --input_shapes=2,3:4,5,6</code> means "foo"
    has a shape of [2, 3] and "bar" has a shape of [4, 5, 6].</li>
</ul>
</li>
<li><code>--std_dev_values</code>, <code>--mean_values</code>. Type: comma-separated list of floats.
    These specify the (de-)quantization parameters of the input array, when it
    is quantized. Only needed if <code>inference_input_type</code> is <code>INT8</code> or <code>UINT8</code>.<ul>
<li>The meaning of <code>mean_values</code> and <code>std_dev_values</code> is as follows: each
    quantized value in the quantized input array will be interpreted as a
    mathematical real number (i.e. as an input activation value) according
    to the following formula:<ul>
<li><code>real_value = (quantized_value - mean_value) / std_dev_value</code>.</li>
</ul>
</li>
<li>When performing float inference (<code>--inference_type=FLOAT</code>) on a
    quantized input, the quantized input would be immediately dequantized by
    the inference code according to the above formula, before proceeding
    with float inference.</li>
<li>When performing quantized inference (<code>inference_type</code> is <code>INT8</code> or
    <code>UINT8</code>), no dequantization is performed by the inference code. However,
    the quantization parameters of all arrays, including those of the input
    arrays as specified by <code>mean_value</code> and <code>std_dev_value</code>, determine the
    fixed-point multipliers used in the quantized inference code.The
    <code>mean_value</code> must be an integer when performing quantized inference.</li>
</ul>
</li>
</ul>
<h2>Transformation flags</h2>
<p><em>Transformation flags</em> specify options of the transformations to be applied to
the graph, i.e. they specify requested properties that the output file should
have.</p>
<ul>
<li>
<p><code>--inference_type</code>. Type: string. Default: <code>FLOAT</code>. Data type of all
    real-number arrays in the output file except for input arrays (defined by
    <code>--inference_input_type</code>). Must be <code>{FLOAT, INT8, UINT8}</code>.</p>
<p>This flag only impacts real-number arrays including float and quantized
arrays. This excludes all other data types including plain integer arrays
and string arrays. Specifically:</p>
<ul>
<li>If <code>FLOAT</code>, then real-numbers arrays will be of type float in the output
    file. If they were quantized in the input file, then they get
    dequantized.</li>
<li>If <code>INT8</code>, then real-numbers arrays will be quantized as int8 in the
    output file. If they were float in the input file, then they get
    quantized.</li>
<li>If <code>UINT8</code>, then real-numbers arrays will be quantized as uint8 in the
    output file. If they were float in the input file, then they get
    quantized.</li>
</ul>
</li>
<li>
<p><code>--inference_input_type</code>. Type: string. Data type of a real-number input
    array in the output file. By default the <code>--inference_type</code> is used as type
    of all of the input arrays. Flag is primarily intended for generating a
    float-point graph with a quantized input array. A Dequantized operator is
    added immediately after the input array. Must be <code>{FLOAT, INT8, UINT8}</code>.</p>
<p>The flag is typically used for vision models taking a bitmap as input but
requiring floating-point inference. For such image models, the uint8 input
is quantized and the quantization parameters used for such input arrays are
their <code>mean_value</code> and <code>std_dev_value</code> parameters.</p>
</li>
<li>
<p><code>--default_ranges_min</code>, <code>--default_ranges_max</code>. Type: floating-point.
    Default value for the (min, max) range values used for all arrays without a
    specified range. Allows user to proceed with quantization of non-quantized
    or incorrectly-quantized input files. These flags produce models with low
    accuracy. They are intended for easy experimentation with quantization via
    "dummy quantization".</p>
</li>
<li>
<p><code>--post_training_quantize</code>. Type: boolean. Default: False. Boolean
    indicating whether to quantize the weights of the converted float model.
    Model size will be reduced and there will be latency improvements (at the
    cost of accuracy).</p>
</li>
<li>
<p><code>--quantize_to_float16</code>. Type: boolean. Default: False. Boolean indicating
    whether to quantize weights to fp16 instead of the default int8 when
    <code>--post_training_quantize=True</code>.</p>
</li>
<li>
<p><code>--reorder_across_fake_quant</code>. Type: boolean. Default: False. Indicates
    whether to reorder FakeQuant nodes in unexpected locations. Used when the
    location of the FakeQuant nodes is preventing graph transformations
    necessary to convert the graph. Results in a graph that differs from the
    quantized training graph, potentially causing differing arithmetic behavior.</p>
</li>
<li>
<p><code>--change_concat_input_ranges</code>. Type: boolean. Default: False. Boolean to
    change behavior of min/max ranges for inputs and outputs of the concat
    operator for quantized models. Changes the ranges of concat operator overlap
    when true.</p>
</li>
<li>
<p><code>--drop_control_dependency</code>. Type: boolean. Default: True. Indicates whether
    to drop control dependencies silently. This is due to TensorFlow Lite not
    supporting control dependencies.</p>
</li>
<li>
<p><code>--target_ops</code>. Type: string. Default: TFLITE_BUILTINS. Experimental flag,
    subject to change. Set of OpsSet options indicating which converter to use.
    Options: TF LITE_BUILTINS,SELECT_TF_OPS,TFLITE_BUILTINS_INT8,EXPER
    IMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8 . One or more option
    may be specified.</p>
</li>
<li>
<p><code>--allow_custom_ops</code>. Type: bool. Default: False. Indicates whether to allow
    custom operations. When False, any unknown operation is an error. When True,
    custom ops are created for any op that is unknown. The developer will need
    to provide these to the TensorFlow Lite runtime with a custom resolver.</p>
</li>
<li>
<p><code>--custom_opdefs</code>. Type: string. String representing a list of custom ops
    OpDefs delineated with commas that are included in the GraphDef. Required
    when using custom operations with <code>--experimental_new_converter</code>.</p>
</li>
</ul>
<h2>Logging flags</h2>
<p>The following flags generate graph visualizations of the graph as
<a href="https://www.graphviz.org/">GraphViz</a> <code>.dot</code> files at various points during
graph transformations:</p>
<ul>
<li><code>--dump_graphviz_dir</code>. Type: string. Specifies the full path of the
    directory to output GraphViz <code>.dot</code> files. Outputs the graph immediately
    after reading in the graph and after all of the transformations have been
    completed.</li>
<li><code>--dump_graphviz_video</code>. Type: boolean. Outputs GraphViz after every graph
    transformation. Requires <code>--dump_graphviz_dir</code> to be specified.</li>
</ul>
<p>The following flag controls generating the conversion logs. The conversion log
includes a protocol buffer of analytics collected during conversion, and an HTML
file where user can preview the conversion summary.</p>
<ul>
<li><code>--conversion_summary_dir</code>. Type: string. Specifies the full path of the
    directory to output conversion logs.</li>
</ul>