<h1>Segmentation</h1>
<p>Image segmentation is the process of partitioning a digital image into multiple
segments (sets of pixels, also known as image objects). The goal of segmentation
is to simplify and/or change the representation of an image into something that
is more meaningful and easier to analyze.</p>
<p>The following image shows the output of the image segmentation model on Android.
The model will create a mask over the target objects with high accuracy.</p>
<p><img src="images/segmentation.gif" class="attempt-right" /></p>
<p>Note: To integrate an existing model, try
<a href="https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_segmenter">TensorFlow Lite Task Library</a>.</p>
<h2>Get started</h2>
<p>If you are new to TensorFlow Lite and are working with Android or iOS, it is
recommended you explore the following example applications that can help you get
started.</p>
<p>You can leverage the out-of-box API from
<a href="../../inference_with_metadata/task_library/image_segmenter">TensorFlow Lite Task Library</a>
to integrate image segmentation models within just a few lines of code. You can
also integrate the model using the
<a href="../../guide/inference#load_and_run_a_model_in_java">TensorFlow Lite Interpreter Java API</a>.</p>
<p>The Android example below demonstrates the implementation for both methods as
<a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/android/lib_task_api">lib_task_api</a>
and
<a href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/android/lib_interpreter">lib_interpreter</a>,
respectively.</p>
<p><a class="button button-primary" href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/android">View
Android example</a></p>
<p><a class="button button-primary" href="https://github.com/tensorflow/examples/tree/master/lite/examples/image_segmentation/ios">View
iOS example</a></p>
<p>If you are using a platform other than Android or iOS, or you are already
familiar with the
<a href="https://www.tensorflow.org/api_docs/python/tf/lite">TensorFlow Lite
APIs</a>, you can download our starter image segmentation model.</p>
<p><a class="button button-primary" href="https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2?lite-format=tflite">Download
starter model</a></p>
<h2>Model description</h2>
<p><em>DeepLab</em> is a state-of-art deep learning model for semantic image segmentation,
where the goal is to assign semantic labels (e.g. person, dog, cat) to every
pixel in the input image.</p>
<h3>How it works</h3>
<p>Semantic image segmentation predicts whether each pixel of an image is
associated with a certain class. This is in contrast to
<a href="../object_detection/overview.md">object detection</a>, which detects
objects in rectangular regions, and
<a href="../image_classification/overview.md">image classification</a>, which
classifies the overall image.</p>
<p>The current implementation includes the following features:</p>
<ol>
  <li>DeepLabv1: We use atrous convolution to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks.</li>
  <li>DeepLabv2: We use atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales with filters at multiple sampling rates and effective fields-of-views.</li>
  <li>DeepLabv3: We augment the ASPP module with image-level feature [5, 6] to capture longer range information. We also include batch normalization [7] parameters to facilitate the training. In particular, we applying atrous convolution to extract output features at different output strides during training and evaluation, which efficiently enables training BN at output stride = 16 and attains a high performance at output stride = 8 during evaluation.</li>
  <li>DeepLabv3+: We extend DeepLabv3 to include a simple yet effective decoder module to refine the segmentation results especially along object boundaries. Furthermore, in this encoder-decoder structure one can arbitrarily control the resolution of extracted encoder features by atrous convolution to trade-off precision and runtime.</li>
</ol>

<h2>Performance benchmarks</h2>
<p>Performance benchmark numbers are generated with the tool
<a href="https://www.tensorflow.org/lite/performance/benchmarks">described here</a>.</p>
<table>
  <thead>
    <tr>
      <th>Model Name</th>
      <th>Model size </th>
      <th>Device </th>
      <th>GPU</th>
      <th>CPU</th>
    </tr>
  </thead>
  <tr>
    <td rowspan = 3>
      <a href="https://tfhub.dev/tensorflow/lite-model/deeplabv3/1/metadata/2?lite-format=tflite">Deeplab v3</a>
    </td>
    <td rowspan = 3>
      2.7 Mb
    </td>
    <td>Pixel 3 (Android 10) </td>
    <td>16ms</td>
    <td>37ms*</td>
  </tr>
   <tr>
     <td>Pixel 4 (Android 10) </td>
    <td>20ms</td>
    <td>23ms*</td>
  </tr>
   <tr>
     <td>iPhone XS (iOS 12.4.1) </td>
     <td>16ms</td>
    <td>25ms** </td>
  </tr>
</table>

<p>* 4 threads used.</p>
<p>** 2 threads used on iPhone for the best performance result.</p>
<h2>Further reading and resources</h2>
<ul>
  <li><a href="https://ai.googleblog.com/2018/03/semantic-image-segmentation-with.html">Semantic Image Segmentation with DeepLab in TensorFlow</a></li>
  <li><a href="https://medium.com/tensorflow/tensorflow-lite-now-faster-with-mobile-gpus-developer-preview-e15797e6dee7">TensorFlow Lite Now Faster with Mobile GPUs (Developer Preview)</a></li>
  <li><a href="https://github.com/tensorflow/models/tree/master/research/deeplab">DeepLab: Deep Labelling for Semantic Image Segmentation</a></li>
</ul>