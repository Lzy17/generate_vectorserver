<h1>AutoGraph reference</h1>
<p><a href="index.md">Index</a></p>
<h2>Operator semantics</h2>
<h3>Definition</h3>
<p>This section describes the semantics of the operators used in code generated by
AutoGraph. Understanding these operators will make it easier to read the
generated code.</p>
<p>AutoGraph operators are Python functions that replace certain Python constructs
in the generated code.</p>
<p>For example, the following statement:</p>
<p><code>if x:
  y = 1
else:
  y = 2</code></p>
<p>Will result in the following generated code:</p>
<p>```
def get_state():
    return (y,)</p>
<p>def set_state(vars_):
    nonlocal y
    (y,) = vars_</p>
<p>def if_body():
    nonlocal y
    y = 1</p>
<p>def else_body():
    nonlocal y
    y = 2
y = ag__.Undefined('y')
ag__.if_stmt(ag__.ld(x), if_body, else_body, get_state, set_state, ('y',), 1)
```</p>
<p>In the example above, <code>ag__.if_stmt</code>, <code>ag__.ld</code> and <code>ag__.Undefined</code> are all
AutoGraph operators.</p>
<p>The source of truth for these operators is the <a href="https://github.com/tensorflow/tensorflow/tree/master/tensorflow/python/autograph/operators">source code</a>
. All public symbols exported by that module is considered an operator.</p>
<h3>Type-based dispatch</h3>
<p>AutoGraph replaces Python statements with operators in order to enable
type-based dispatch. If Python didn't support things like <code>__add__</code>, then
AutoGraph would already have an <code>add</code> operator.</p>
<p>Dispatch means simply that the operator does different things based on the type
of input.</p>
<p>Generally, the dispatch follows these rules:
 * if the input is a type that would execute normally under Python (this is also
   referred to as "the default path"), then AutoGraph always reverts to the
   corresponding Python operator. For example, <code>ag__.not(False)</code> always has the
   same result as <code>not False</code>.
 * if the input is a TensorFlow type, then AutoGraph typically dispatches to an
   equivalent TensorFlow API, performs additional checks or just raises an
   error. For example, <code>ag__.eq(tf.constant(1), tf.constant(2))</code> has the same
   result as <code>tf.math.equal(tf.constant(1), tf.constant(2))</code>.</p>
<p>The first rule above means that if you convert normal, non-TensorFlow code with
AutoGraph and call it with non-TensorFlow inputs, executing the generated code
should be no different than executing the original.</p>
<h3>Functional form</h3>
<p>All AutoGraph operators use pure functional forms. This may sometimes mean that
expressions which normally appear bare in Python, are wrapped inside a function
(also known as thunk). If a Python statement appears as just <code>foo</code>, then a
corresponding thunk is <code>lambda: foo</code>.</p>
<h3>Operator list</h3>
<h4>Conditional expressions</h4>
<p><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/operators/conditional_expressions.py">Source</a></p>
<h5><code>if_exp</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/conditional_expressions.py#L27">Source</a></p>
<p>The Python conditional statement: <code>foo if bar else baz</code>.</p>
<p>Args:
  cond: expression condition; same as <code>cond</code> in <code>_ if cond else _</code>.
  if_true: true value (as thunk); same as <code>lambda: x</code> in <code>x if _ else _</code>.
  if_false: false value (as thunk); same as <code>lambda: x</code> in <code>_ if _ else x</code>.
  expr_repr: human readable string representing <code>cond</code>. Used for error messages.</p>
<p>Example:</p>
<p><code>true_val if cond else false_val</code></p>
<p><code>ag__.if_expr(cond, lambda: true_val, lambda: false_val, 'cond')</code></p>
<p>Dispatch on <code>cond</code>:</p>
<ul>
<li>default: to Python if-else statement.</li>
<li>tf.Tensor: to <code>tf.cond</code>, checking that <code>true_val</code> and <code>false_val</code> have
    compatible shape and type.</li>
</ul>
<h4>Control flow</h4>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/control_flow.py">Source</a></p>
<p>Unlike Python, AutoGraph control flow operators use explicit control flow
variables, which include all symbols which are modified by the control flow.</p>
<p>For example, the code below has a single loop variable, <code>x</code>:</p>
<p><code>while x &lt; 3:
  x = x + 1</code></p>
<p>In addition, control flow that is dispatched to non-Python implementation is
subject to restrictions of the respective implementations. For example,
<code>tf.while_loop</code> requires that all loop variables have supported types (e.g.
<code>Tensor</code> of consistent shape and dtype).</p>
<h5><code>for_stmt</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/control_flow.py#L369">Source</a></p>
<p>For loop: <code>for var in target: body</code>, extended with a per-iteration
condition to handle early termination (e.g. due to a <code>break</code>).</p>
<p>Args:</p>
<ul>
<li>iter_: iteration target; same as <code>n</code> in <code>for _ in n</code>.</li>
<li>extra_test: optional extra per-iteration condition (as thunk).</li>
<li>body: loop body (as unary thunk); same as <code>def body(i): &lt;b&gt;</code> in <code>for i in _:
    &lt;b&gt;</code>.</li>
<li>get_state: returns the current value of the loop variables</li>
<li>set_state: sets new values into the loop variables</li>
<li>symbol_names: human readable string representing each loop variable. Used
    for error messages.</li>
<li>opts: additional, implementation-specific, keyword arguments.</li>
</ul>
<p>Example:</p>
<p><code>for i in range(3):
  j = j + i</code></p>
<p>```
def get_state():
    return (j,)</p>
<p>def set_state(vars_):
    nonlocal j
    (j,) = vars_</p>
<p>def loop_body(itr):
    nonlocal j
    i = itr
    j = j + i</p>
<p>ag__.for_stmt(range(3), None, loop_body, get_state, set_state, ('j',), {})
```</p>
<p>Example (using extra_test):</p>
<p><code>for i in range(3):
  if i &gt; 2:
    break
  j = j + i</code></p>
<p>```
def get_state():
    return (j,)</p>
<p>def set_state(vars_):
    nonlocal j
    (j,) = vars_</p>
<p>def loop_body(itr):
    nonlocal j
    i = itr
    j = j + i</p>
<p>def extra_test():
    return not(i &lt;= 2)</p>
<p>ag__.for_stmt(range(3), extra_test, loop_body, get_state, set_state, ('j',), {})
```</p>
<p>Dispatch on <code>iter_</code>:</p>
<ul>
<li>default: to Python for loop (accounting for <code>extra_test</code>).</li>
<li><code>tf.Tensor</code> produced by <code>tf.range</code>: to <code>tf.while_loop</code>, removing the
    <code>tf.range</code>.</li>
<li><code>tf.Tensor</code>, <code>tf.RagedTensor</code>: to <code>tf.while_loop</code>, checking the loop vars
    for consistency. <code>opts</code> forwarded to <code>tf.while_loop</code>. Iterates over the
    outermost dimension of the tensor (similar to <code>tf.map_fn</code>).</li>
<li><code>tf.data.Dataset</code>: to <code>tf.data.Dataset.take_while</code>, checking the loop vars
    for consistency.</li>
<li><code>tf.data.Iterator</code>, <code>tf.distribute.Iterator</code>: to <code>tf.while_loop</code> called on
    the iterator's <code>get_next_as_optional</code>, checking the loop vars for
    consistency.</li>
<li><code>tf.distribute.Iterable</code>: to <code>tf.distribute.Iterable.reduce</code>.</li>
</ul>
<h5><code>if_stmt</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/control_flow.py#L1125">Source</a></p>
<p>If statement: <code>if cond: body else: orelse-body</code>.</p>
<p>Args:</p>
<ul>
<li>cond: if condition; same as <code>cond</code> in <code>if cond</code>.</li>
<li>body: true branch (as unary thunk); same as <code>def body(): &lt;b&gt;</code> in <code>if _:
    &lt;b&gt;</code>.</li>
<li>orelse: false branch (as unary thunk); same as <code>def body(): &lt;b&gt;</code> in <code>if _:
    &lt;b&gt;</code>.</li>
<li>get_state: returns the current value of the conditional variables</li>
<li>set_state: sets new values into the conditional variables</li>
<li>symbol_names: human readable string representing each conditional variable.
    Used for error messages.</li>
<li>nouts: number of output conditional variables. Not all conditional variables
    are outputs - some are just inputs. The first nouts values in get_state and
    set_state are the conditional outputs.</li>
</ul>
<p>Example:</p>
<p><code>if k &gt; 1:
  j = j + i</code></p>
<p>```
def get_state():
    return (j, i)</p>
<p>def set_state(vars_):
    nonlocal j, i
    (j, i) = vars_</p>
<p>def body():
    nonlocal j, i
    j = j + i</p>
<p>def orelse():
    pass</p>
<p>ag__.if_stmt(k &gt; 1, body, orelse, get_state, set_state, ('j', 'i'), 1)
```</p>
<p>Dispatch on <code>cond</code>:</p>
<ul>
<li>default: to Python if statement.</li>
<li><code>tf.Tensor</code>: to <code>tf.cond</code>, removing the <code>tf.range</code>.</li>
</ul>
<h5><code>while_stmt</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/control_flow.py#L811">Source</a></p>
<p>While loop: <code>while cond: body</code>.</p>
<p>Args:</p>
<ul>
<li>test: loop condition (as thunk); same as <code>def test(): cond</code> in <code>while cond</code>.</li>
<li>body: loop body (as thunk); same as <code>def body(): &lt;b&gt;</code> in <code>while _: &lt;b&gt;</code>.</li>
<li>get_state: returns the current value of the loop variables</li>
<li>set_state: sets new values into the loop variables</li>
<li>symbol_names: human readable string representing each loop variable. Used
    for error messages.</li>
<li>opts: additional, implementation-specific, keyword arguments.</li>
</ul>
<p>Example:</p>
<p><code>while j &gt; 10:
  j = j + i</code></p>
<p>```
def get_state():
    return (j,)</p>
<p>def set_state(vars_):
    nonlocal j
    (j,) = vars_</p>
<p>def loop_test():
    nonlocal j
    return j &gt; 10</p>
<p>def loop_body():
    nonlocal j
    j = j + i</p>
<p>ag__.while_stmt(loop_test, loop_body, get_state, set_state, ('j',), {})
```</p>
<p>Dispatch on return type of <code>test</code>:</p>
<ul>
<li>default: to Python while loop.</li>
<li><code>tf.Tensor</code>: to <code>tf.while_loop</code>.</li>
</ul>
<h4>Data structures</h4>
<p><a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/operators/data_structures.py">Source</a></p>
<h5><code>list_append</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/data_structures.py#L171">Source</a></p>
<p>List append operation: <code>l.append(x)</code>. Callers should assume that the list
argument is modified, if that is possible.</p>
<p>Args:</p>
<ul>
<li>list_: a list-like value.</li>
<li>x: value to append to list.</li>
</ul>
<p>Returns:</p>
<ul>
<li>same as list_, with an appended value.</li>
</ul>
<p>Example:</p>
<p><code>l.append(x)</code></p>
<p><code>l = ag__.list_append(l, x)</code></p>
<p>Dispatch on <code>list_</code>:</p>
<ul>
<li>default: to <code>list_.append</code>.</li>
<li><code>tf.Tensor</code>: to <code>tf.raw_ops.tensor_list_push_back</code>.</li>
<li><code>tf.TensorArray</code>: to <code>tf.TensorArray.write</code>.</li>
</ul>
<h5><code>list_pop</code></h5>
<p><a href="https://github.com/tensorflow/tensorflow/blob/bacd16a95d5a6f3d5081e3d56c515671c784d289/tensorflow/python/autograph/operators/data_structures.py#L235">Source</a></p>
<p>List pop operation: <code>l.pop(i)</code>. Callers should assume that the list
argument is modified, if that is possible.</p>
<p>Args:</p>
<ul>
<li>list_: a list-like value.</li>
<li>i: optional index to remove from.</li>
<li>opts: optional, implementation-specific arguments.</li>
</ul>
<p>Returns:</p>
<ul>
<li>new_list: same as list_, with the value removed</li>
<li>x: the value that was removed</li>
</ul>
<p>Example:</p>
<p><code>x = l.pop()</code></p>
<p><code>l, x = ag__.list_pop(l)</code></p>
<p>Dispatch on <code>list_</code>:</p>
<ul>
<li>default: to <code>list_.pop</code>.</li>
<li><code>tf.Tensor</code>: to <code>tf.raw_ops.tensor_list_pop_back</code>.</li>
</ul>
<h5><code>list_stack</code></h5>
<h5><code>ListPopOpts</code></h5>
<h5><code>ListStackOpts</code></h5>
<h5><code>new_list</code></h5>
<h3>Exceptions</h3>
<h5><code>assert_stmt</code></h5>
<h3>Boolean</h3>
<h5><code>and_</code></h5>
<h5><code>eq</code></h5>
<h5><code>not_</code></h5>
<h5><code>not_eq</code></h5>
<h5><code>or_</code></h5>
<h3>Python built-ins</h3>
<h5><code>float_</code></h5>
<h5><code>int_</code></h5>
<h5><code>len_</code></h5>
<h5><code>print_</code></h5>
<h5><code>range_</code></h5>
<h3>Slicing</h3>
<h5><code>get_item</code></h5>
<h5><code>GetItemOpts</code></h5>
<h5><code>set_item</code></h5>
<h3>Variables</h3>
<h5><code>ld</code></h5>
<h5><code>ldu</code></h5>
<h5><code>Undefined</code></h5>
<h5><code>UndefinedReturnValue</code></h5>