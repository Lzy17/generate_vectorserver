<h1>PyTorch Glossary</h1>
<!-- toc -->

<ul>
<li><a href="#operation-and-kernel">Operation and Kernel</a></li>
<li><a href="#aten">ATen</a></li>
<li><a href="#operation">Operation</a></li>
<li><a href="#native-operation">Native Operation</a></li>
<li><a href="#custom-operation">Custom Operation</a></li>
<li><a href="#kernel">Kernel</a></li>
<li><a href="#compound-operation">Compound Operation</a></li>
<li><a href="#composite-operation">Composite Operation</a></li>
<li><a href="#non-leaf-operation">Non-Leaf Operation</a></li>
<li><a href="#leaf-operation">Leaf Operation</a></li>
<li><a href="#device-kernel">Device Kernel</a></li>
<li><a href="#compound-kernel">Compound Kernel</a></li>
<li><a href="#jit-compilation">JIT Compilation</a></li>
<li><a href="#jit">JIT</a></li>
<li><a href="#torchscript">TorchScript</a></li>
<li><a href="#tracing">Tracing</a></li>
<li><a href="#scripting">Scripting</a></li>
</ul>
<!-- tocstop -->

<h1>Operation and Kernel</h1>
<h2>ATen</h2>
<p>Short for "A Tensor Library". The foundational tensor and mathematical
operation library on which all else is built.</p>
<h2>Operation</h2>
<p>A unit of work. For example, the work of matrix multiplication is an operation
called aten::matmul.</p>
<h2>Native Operation</h2>
<p>An operation that comes natively with PyTorch ATen, for example aten::matmul.</p>
<h2>Custom Operation</h2>
<p>An Operation that is defined by users and is usually a Compound Operation.
For example, this
<a href="https://pytorch.org/docs/stable/notes/extending.html">tutorial</a> details how
to create Custom Operations.</p>
<h2>Kernel</h2>
<p>Implementation of a PyTorch operation, specifying what should be done when an
operation executes.</p>
<h2>Compound Operation</h2>
<p>A Compound Operation is composed of other operations. Its kernel is usually
device-agnostic. Normally it doesn't have its own derivative functions defined.
Instead, AutoGrad automatically computes its derivative based on operations it
uses.</p>
<h2>Composite Operation</h2>
<p>Same as Compound Operation.</p>
<h2>Non-Leaf Operation</h2>
<p>Same as Compound Operation.</p>
<h2>Leaf Operation</h2>
<p>An operation that's considered a basic operation, as opposed to a Compound
Operation. Leaf Operation always has dispatch functions defined, usually has a
derivative function defined as well.</p>
<h2>Device Kernel</h2>
<p>Device-specific kernel of a leaf operation.</p>
<h2>Compound Kernel</h2>
<p>Opposed to Device Kernels, Compound kernels are usually device-agnostic and belong to Compound Operations.</p>
<h1>JIT Compilation</h1>
<h2>JIT</h2>
<p>Just-In-Time Compilation.</p>
<h2>TorchScript</h2>
<p>An interface to the TorchScript JIT compiler and interpreter.</p>
<h2>Tracing</h2>
<p>Using <code>torch.jit.trace</code> on a function to get an executable that can be optimized
using just-in-time compilation.</p>
<h2>Scripting</h2>
<p>Using <code>torch.jit.script</code> on a function to inspect source code and compile it as
TorchScript code.</p>