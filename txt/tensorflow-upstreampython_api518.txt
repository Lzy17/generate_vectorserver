<h2>Python API Tutorials</h2>
<ul>
<li><a href="#parameters-and-shapes">Parameters and Shapes</a></li>
<li><a href="#float-operations">Float Operations</a></li>
<li><a href="#time-and-memory">Time and Memory</a></li>
<li><a href="#visualize">Visualize</a></li>
<li><a href="#multi-step-profiling">Multi-step Profiling</a></li>
</ul>
<p><code>import tensorflow as tf</code>.</p>
<h3>Parameters and Shapes.</h3>
<p>```python</p>
<h1>Print trainable variable parameter statistics to stdout.</h1>
<p>ProfileOptionBuilder = tf.profiler.ProfileOptionBuilder</p>
<p>param_stats = tf.profiler.profile(
    tf.get_default_graph(),
    options=ProfileOptionBuilder.trainable_variables_parameter())</p>
<h1>Use code view to associate statistics with Python codes.</h1>
<p>opts = ProfileOptionBuilder(
    ProfileOptionBuilder.trainable_variables_parameter()
    ).with_node_names(show_name_regexes=['.<em>my_code1.py.</em>', '.<em>my_code2.py.</em>']
    ).build()
param_stats = tf.profiler.profile(
    tf.get_default_graph(),
    cmd='code',
    options=opts)</p>
<h1>param_stats can be tensorflow.tfprof.GraphNodeProto or</h1>
<h1>tensorflow.tfprof.MultiGraphNodeProto, depending on the view.</h1>
<h1>Let's print the root below.</h1>
<p>sys.stdout.write('total_params: %d\n' % param_stats.total_parameters)
```</p>
<h3>Float Operations</h3>
<h4>Note: See <a href="profile_model_architecture.md#caveats">Caveats</a> in "Profile Model Architecture" Tutorial</h4>
<p>``` python</p>
<h1>Print to stdout an analysis of the number of floating point operations in the</h1>
<h1>model broken down by individual operations.</h1>
<p>tf.profiler.profile(
    tf.get_default_graph(),
    options=tf.profiler.ProfileOptionBuilder.float_operation())
```</p>
<h3>Time and Memory</h3>
<p>You will first need to run the following set up in your model in order to
compute the memory and timing statistics.</p>
<p>```python</p>
<h1>Generate the RunMetadata that contains the memory and timing information.</h1>
<h1></h1>
<h1>Note: When run on accelerator (e.g. GPU), an operation might perform some</h1>
<h1>cpu computation, enqueue the accelerator computation. The accelerator</h1>
<h1>computation is then run asynchronously. The profiler considers 3</h1>
<h1>times: 1) accelerator computation. 2) cpu computation (might wait on</h1>
<h1>accelerator). 3) the sum of 1 and 2.</h1>
<h1></h1>
<p>run_metadata = tf.RunMetadata()
with tf.Session() as sess:
  _ = sess.run(train_op,
               options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),
               run_metadata=run_metadata)
```</p>
<p>Finally, you may run <code>tf.profiler.profile</code> to explore the timing and memory
information of the model.</p>
<p>``` python</p>
<h1>Print to stdout an analysis of the memory usage and the timing information</h1>
<h1>broken down by python codes.</h1>
<p>ProfileOptionBuilder = tf.profiler.ProfileOptionBuilder
opts = ProfileOptionBuilder(ProfileOptionBuilder.time_and_memory()
    ).with_node_names(show_name_regexes=['.<em>my_code.py.</em>']).build()</p>
<p>tf.profiler.profile(
    tf.get_default_graph(),
    run_meta=run_metadata,
    cmd='code',
    options=opts)</p>
<h1>Print to stdout an analysis of the memory usage and the timing information</h1>
<h1>broken down by operation types.</h1>
<p>tf.profiler.profile(
    tf.get_default_graph(),
    run_meta=run_metadata,
    cmd='op',
    options=tf.profiler.ProfileOptionBuilder.time_and_memory())
```</p>
<h3>Visualize</h3>
<p><code>To visualize the result of Python API results:
Call `with_step(0).with_timeline_output(filename)` to generate a timeline json file.
Open a Chrome Browser, type URL `chrome://tracing`, and load the json file.</code></p>
<p>Below are 2 examples of graph view and scope view.</p>
<p><left>
<img alt="CodeTimeline" src="graph_timeline.png" />
<img alt="CodeTimeline" src="scope_timeline.png" />
</left></p>
<h3>Multi-step Profiling</h3>
<p>tfprof allows you to profile statistics across multiple steps.</p>
<p>```python
opts = model_analyzer.PRINT_ALL_TIMING_MEMORY.copy()
opts['account_type_regexes'] = ['.*']</p>
<p>with session.Session() as sess:
  r1, r2, r3 = lib.BuildSplittableModel()
  sess.run(variables.global_variables_initializer())</p>
<p># Create a profiler.
  profiler = model_analyzer.Profiler(sess.graph)
  # Profile without RunMetadata of any step.
  pb0 = profiler.profile_name_scope(opts)</p>
<p>run_meta = config_pb2.RunMetadata()
  _ = sess.run(r1,
               options=config_pb2.RunOptions(
                   trace_level=config_pb2.RunOptions.FULL_TRACE),
               run_metadata=run_meta)</p>
<p># Add run_meta of step 1.
  profiler.add_step(1, run_meta)
  pb1 = profiler.profile_name_scope(opts)</p>
<p>run_meta2 = config_pb2.RunMetadata()
  _ = sess.run(r2,
               options=config_pb2.RunOptions(
                   trace_level=config_pb2.RunOptions.FULL_TRACE),
               run_metadata=run_meta2)
  # Add run_meta of step 2.
  profiler.add_step(2, run_meta2)
  pb2 = profiler.profile_name_scope(opts)</p>
<p>run_meta3 = config_pb2.RunMetadata()
  _ = sess.run(r3,
               options=config_pb2.RunOptions(
                   trace_level=config_pb2.RunOptions.FULL_TRACE),
               run_metadata=run_meta3)
  # Add run_meta of step 3.
  profiler.add_step(3, run_meta3)
  pb3 = profiler.profile_name_scope(opts)
```</p>